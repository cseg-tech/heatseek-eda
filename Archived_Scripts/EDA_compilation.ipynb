{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Overview\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* I Data Overview\n",
    "    * I.1 What do our tenants look like?\n",
    "    * I.2 How is the quality of the data?\n",
    "    * I.3 Conclusion & Impact\n",
    "* II Quantifying Violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1 What does our tenants data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_import(filepath):\n",
    "    \"\"\"\n",
    "    Given a filepath to a dataset, return a list of dataframes\n",
    "    per user.\n",
    "    \"\"\"\n",
    "    # open the file\n",
    "    with open(filepath, 'r') as inputfile:\n",
    "        # import csv with pandas\n",
    "        file_df = pd.read_csv(inputfile, header = 0)\n",
    "        \n",
    "        file_df['created_at'] = pd.to_datetime(file_df['created_at'], format=\"%Y-%m-%d %H:%M:%S\", utc=True)\n",
    "        file_df['created_at'] = file_df['created_at'].dt.tz_convert(pytz.timezone('US/Eastern'))\n",
    "        # determine list of unique users\n",
    "        userlist = file_df['user_id'].tolist()\n",
    "        userset = set(userlist)\n",
    "        \n",
    "        user_list = []\n",
    "        # iterate through each user and save out data\n",
    "        for user in userset:\n",
    "            user_df = file_df.loc[file_df['user_id'] == user]\n",
    "            #user_df['user_id'] = user\n",
    "            user_df.reset_index(drop=True, inplace=True)\n",
    "            user_list.append(user_df)\n",
    "\n",
    "    return file_df, user_list\n",
    "\n",
    "def summary_stats(file_dataset, user_dataset):\n",
    "    \"\"\"\n",
    "    Print some very basic information about the provided dataset.\n",
    "    :param file_dataset: first dataset returned by user_import()\n",
    "    :type file_dataset: DataFrame\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    print('Number of unique tenants: ', str(len(user_dataset)))\n",
    "    \n",
    "    print('Number of datapoints: ', str(len(file_dataset)))\n",
    "    \n",
    "    from_date = min(file_dataset['created_at'])\n",
    "    to_date = max(file_dataset['created_at'])\n",
    "    print('Range of datapoints: ', from_date.strftime(\"%Y-%m-%d %H:%M:%S\"), ' to ', \\\n",
    "          to_date.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_plot(user_dataset):\n",
    "    \"\"\"\n",
    "    Plot the time coverage of individual user data.\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    # Define a new DataFrame for our use\n",
    "    coverage_df = pd.DataFrame(columns=['from', 'to', 'len', 'user_id'])\n",
    "    \n",
    "    # Calculate each of the columns\n",
    "    for user_df in user_dataset:\n",
    "        # Earliest timestamp\n",
    "        user_from = min(user_df['created_at'])\n",
    "        # Latest timestamp\n",
    "        user_to = max(user_df['created_at'])\n",
    "        # Range of timestamps\n",
    "        user_range = user_to - user_from\n",
    "        # Fill in coverage DataFrame\n",
    "        coverage_df = coverage_df.append({'from': user_from, 'to':user_to, 'len': user_range, \\\n",
    "                                          'user_id': user_df.loc[0, 'user_id']}, ignore_index=True)\n",
    "    \n",
    "    # Sort users by range, so users with longest uptime is first\n",
    "    coverage_df.sort_values('len', ascending=False, inplace=True)\n",
    "    coverage_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # matplotlib magic\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(17,22))\n",
    "    ax.xaxis_date()\n",
    "    y_labels =[]\n",
    "    deltas = []\n",
    "    lefts = []\n",
    "    \n",
    "    # For each user...\n",
    "    for i in range(len(coverage_df)):\n",
    "        # User id label for the y-axis\n",
    "        y_labels.append(str(coverage_df.iloc[i]['user_id']))\n",
    "        # Convert datetime into matplotlib date number format\n",
    "        from_num = mdates.date2num(coverage_df.iloc[i]['from'])\n",
    "        to_num = mdates.date2num(coverage_df.iloc[i]['to'])\n",
    "        # Recalculate range in matplotlib date number format\n",
    "        delta_num = to_num - from_num\n",
    "        deltas.append(delta_num)\n",
    "        lefts.append(from_num)\n",
    "    print(y_labels)\n",
    "    \n",
    "    # Plot using \"horizontal bar graph\" format\n",
    "    # See matplotlib docs for definitions of each function\n",
    "    ax.barh(range(len(coverage_df)), deltas, left=lefts, height=0.7, align='center', zorder=3)\n",
    "    ax.set_xlim((lefts[0]-10, lefts[0]+deltas[0]+10))\n",
    "    ax.set_yticks(range(len(coverage_df)))\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_ylabel('user_id', fontweight='bold', fontsize='large')\n",
    "    ax.set_xlabel('time', fontweight='bold', fontsize='large')\n",
    "    ax.set_title('2017-2018 Heat Season Tenant Data Time-Coverage Summary', fontweight='bold', fontsize='large')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(b=True, which='major', axis='both', linestyle='--', zorder=1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dataset, user_dataset = user_import('data/clean_100117_053118.csv')\n",
    "summary_stats(file_dataset, user_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_plot(user_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 What is the quality of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether data is actually coming in hourly; calculate all data intervals\n",
    "def interval_calc(user_dataset):\n",
    "    \"\"\"\n",
    "    Iterate through all users and calculate the intervals between data points.\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    intervals = []\n",
    "    users = []\n",
    "    for user in user_dataset:\n",
    "        temp = []\n",
    "        for i in range(0, len(user)-1):\n",
    "            now = user.iloc[i]['created_at']\n",
    "            pre = user.iloc[i+1]['created_at']\n",
    "            delta = now - pre # we expect this to be 3600\n",
    "            temp.append((delta.total_seconds()) / 3600.0)\n",
    "        intervals.append(temp)\n",
    "        users.append(user.iloc[0]['user_id'])\n",
    "    return intervals\n",
    "\n",
    "# def plot_intervals(intervals):\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "#     ax.hist(all_intervals, bins=np.logspace(np.log10(0.001),np.log10(1000), 100))\n",
    "#     #ax.set_yscale('log')\n",
    "#     ax.set_ylim(0,50)\n",
    "#     ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = interval_calc(user_dataset)\n",
    "all_intervals = np.array([intv for sub in intervals for intv in sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intervals exactly 1 hour apart:')\n",
    "print(len([a for a in all_intervals if (a <= 1.00 and a >= 1.00)]) / len([a for a in all_intervals]))\n",
    "print('Intervals 1 hour +- 1 second apart:')\n",
    "print(len([a for a in all_intervals if (a <= 1.000277778 and a >= 0.999722222)]) / len([a for a in all_intervals]))\n",
    "print('Intervals 1 hour +- 2 seconds apart:')\n",
    "print(len([a for a in all_intervals if (a <= 1.000555556 and a >= 0.999444444)]) / len([a for a in all_intervals]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdoor_uptime(file_dataset):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of all measurements that have outdoor temperature.\n",
    "    :param file_dataset: first dataset returned by user_import()\n",
    "    :type file_dataset: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # count the number of rows that don't have NaN values in the outdoor_temp column.\n",
    "    outdoor_dataset = file_dataset.loc[file_dataset['outdoor_temp'].notna()]\n",
    "    return len(outdoor_dataset) / len(file_dataset)\n",
    "\n",
    "od_up = outdoor_uptime(file_dataset)\n",
    "print('The outdoor_temp uptime is ', od_up )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_uptime(user_dataset):\n",
    "    \"\"\"\n",
    "    Calculate the uptime of measurements taken by each user's sensor.\n",
    "    We expect one measurement per hour, or 24 measurements every day.\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    uptimes = []\n",
    "    for user in user_dataset:\n",
    "        # Determine the time the sensor was installed for\n",
    "        from_date = min(user['created_at'])\n",
    "        to_date = max(user['created_at'])\n",
    "        date_range = to_date - from_date\n",
    "        \n",
    "        # expected data points\n",
    "        # note the fenceposted +1\n",
    "        exp_len = int(date_range.total_seconds() / 3600.0) + 1\n",
    "        \n",
    "        # calculate the uptime\n",
    "        if exp_len == 0:\n",
    "            perc = 0\n",
    "        else:\n",
    "            # number of datapoints / expected number of datapoints\n",
    "            perc = len(user) / exp_len\n",
    "        uptimes.append(perc)\n",
    "    return uptimes\n",
    "\n",
    "def plot_uptime(uptime):\n",
    "    \"\"\"\n",
    "    Plot the uptime of measurements taken by each user's sensor as a histogram.\n",
    "    :param uptime: output from overall_uptime()\n",
    "    :type uptime: list\n",
    "    \"\"\"\n",
    "    # simple matplotlib histogram\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "    ax.hist(uptime, 20)\n",
    "    ax.set_title('2017-2018 Heat Season Tenant Data Uptime')\n",
    "    ax.set_xlabel('Uptime Percentage (assuming data every 1hr)')\n",
    "    ax.set_ylabel('Number of Tenants')\n",
    "    \n",
    "total_up = overall_uptime(user_dataset)\n",
    "print(total_up)\n",
    "plot_uptime(total_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Pretty good uptime, one of the datapoints was collected twice as often (every 30)\n",
    "* Variation is motivator for cumulative instead of consecutive metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_daynight(file_dataset):\n",
    "    \"\"\"\n",
    "    Split overall dataset into day and night\n",
    "    :param file_dataset: first dataset returned by user_import()\n",
    "    :type file_dataset: DataFrame\n",
    "    \"\"\"\n",
    "    # day and night time definitions\n",
    "    day = [hr for hr in range(6, 22)]\n",
    "    night = [22, 23, 0, 1, 2, 3, 4, 5]\n",
    "    # pull out the rows that have 'created_at' column values with hour values in either range\n",
    "    # .dt interprets the Series as datetime\n",
    "    # .hour gets the hour value\n",
    "    # .isin checks if the value is in a list\n",
    "    day_dataset = file_dataset.loc[file_dataset['created_at'].dt.hour.isin(day)]\n",
    "    night_dataset = file_dataset.loc[file_dataset['created_at'].dt.hour.isin(night)]\n",
    "    \n",
    "    return day_dataset, night_dataset\n",
    "\n",
    "def day_scatter(file_dataset):\n",
    "    \"\"\"\n",
    "    Plot a scatterplot of the daytime dataset\n",
    "    :param file_dataset: first dataset returned by split_daynight()\n",
    "    :type file_dataset: DataFrame\n",
    "    \"\"\"\n",
    "    # Split the dataset into violation and non-violation\n",
    "    vio_true = file_dataset.loc[file_dataset['violation'] == True]\n",
    "    vio_false = file_dataset.loc[file_dataset['violation'] == False]\n",
    "    \n",
    "    # For both datasets, get the Series for indoor/outdoor temperatures, \n",
    "    # as well as the timestamp for heatmapping\n",
    "    vt_yval = vio_true['temp']\n",
    "    vt_xval = vio_true['outdoor_temp']\n",
    "    vt_c = mdates.date2num(vio_true['created_at'])\n",
    "    \n",
    "    vf_yval = vio_false['temp']\n",
    "    vf_xval = vio_false['outdoor_temp']\n",
    "    vf_c = mdates.date2num(vio_false['created_at'])\n",
    "    \n",
    "    # Getting the min and max timestamps for accurate heatmapping\n",
    "    cb_min = min((min(vf_c), min(vt_c)))\n",
    "    cb_max = max((max(vf_c), max(vt_c)))\n",
    "    \n",
    "    # Defining the datapoints to plot the temp violation cutoffs\n",
    "    base = range(0, 100)\n",
    "    day_room = [68] * 100\n",
    "    day_out = [55] * 100\n",
    "    \n",
    "    # matplotlib magic\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    ax1.scatter(vf_xval, vf_yval, c='g', marker='.', label='nominal')\n",
    "    ax1.scatter(vt_xval, vt_yval, c='r', marker='.', label='violation')\n",
    "    ax1.plot(base, base, 'b-')\n",
    "    ax1.plot(base, day_room, 'k-')\n",
    "    ax1.plot(day_out, base, 'k-')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax1.set_xlabel('outdoor temp. (F)')\n",
    "    ax1.set_ylabel('indoor temp. (F)')\n",
    "    fig.suptitle('2017-2018 Heat Season Tenant Daytime Indoor vs Outdoor Temp', fontsize='x-large')\n",
    "    \n",
    "    sc = ax2.scatter(vf_xval, vf_yval, c=vf_c, marker='.', cmap='winter', vmin=cb_min, vmax=cb_max)\n",
    "    ax2.scatter(vt_xval, vt_yval, c=vt_c, marker='.', cmap='winter', vmin=cb_min, vmax=cb_max)\n",
    "    ax2.plot(base, base, 'b-')\n",
    "    ax2.plot(base, day_room, 'k-')\n",
    "    ax2.plot(day_out, base, 'k-')\n",
    "    \n",
    "    ax2.set_xlabel('outdoor temp. (F)')\n",
    "    ax2.set_ylabel('indoor temp. (F)')\n",
    "    #ax2.set_title('2017-2018 Heat Season Tenant Indoor vs Outdoor Temp')\n",
    "    \n",
    "    cbar = fig.colorbar(sc, ax = np.array([ax1,ax2]).ravel().tolist(), ticks=[cb_min, cb_max])\n",
    "    cbar.ax.set_yticklabels([mdates.num2date(cb_min, pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d\"), \\\n",
    "                            mdates.num2date(cb_max, pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d\")])\n",
    "    \n",
    "def night_scatter(file_dataset):\n",
    "    \"\"\"\n",
    "    Plot a scatterplot of the nighttime dataset\n",
    "    :param file_dataset: second dataset returned by split_daynight()\n",
    "    :type file_dataset: DataFrame\n",
    "    \"\"\"\n",
    "    # Split the dataset into violation and non-violation\n",
    "    vio_true = file_dataset.loc[file_dataset['violation'] == True]\n",
    "    vio_false = file_dataset.loc[file_dataset['violation'] == False]\n",
    "    \n",
    "    # For both datasets, get the Series for indoor/outdoor temperatures, \n",
    "    # as well as the timestamp for heatmapping\n",
    "    vt_yval = vio_true['temp']\n",
    "    vt_xval = vio_true['outdoor_temp']\n",
    "    vt_c = mdates.date2num(vio_true['created_at'])\n",
    "    \n",
    "    vf_yval = vio_false['temp']\n",
    "    vf_xval = vio_false['outdoor_temp']\n",
    "    vf_c = mdates.date2num(vio_false['created_at'])\n",
    "    \n",
    "    # Getting the min and max timestamps for accurate heatmapping\n",
    "    cb_min = min((min(vf_c), min(vt_c)))\n",
    "    cb_max = max((max(vf_c), max(vt_c)))\n",
    "\n",
    "    # Defining the datapoints to plot the temp violation cutoffs\n",
    "    base = range(0, 100)\n",
    "    night_room = [62] * 100\n",
    "    \n",
    "    # matplotlib magic\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    ax1.scatter(vf_xval, vf_yval, c='g', marker='.', label='nominal')\n",
    "    ax1.scatter(vt_xval, vt_yval, c='r', marker='.', label='violation')\n",
    "    ax1.plot(base, base, 'b-')\n",
    "    ax1.plot(base, night_room, 'k-')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax1.set_xlabel('outdoor temp. (F)')\n",
    "    ax1.set_ylabel('indoor temp. (F)')\n",
    "    fig.suptitle('2017-2018 Heat Season Tenant Nighttime Indoor vs Outdoor Temp', fontsize='x-large')\n",
    "    \n",
    "    sc = ax2.scatter(vf_xval, vf_yval, c=vf_c, marker='.', cmap='winter', vmin=cb_min, vmax=cb_max)\n",
    "    ax2.scatter(vt_xval, vt_yval, c=vt_c, marker='.', cmap='winter', vmin=cb_min, vmax=cb_max)\n",
    "    ax2.plot(base, base, 'b-')\n",
    "    ax2.plot(base, night_room, 'k-')\n",
    "    \n",
    "    ax2.set_xlabel('outdoor temp. (F)')\n",
    "    ax2.set_ylabel('indoor temp. (F)')\n",
    "    #ax2.set_title('2017-2018 Heat Season Tenant Indoor vs Outdoor Temp')\n",
    "    \n",
    "    cbar = fig.colorbar(sc, ax = np.array([ax1,ax2]).ravel().tolist(), ticks=[cb_min, cb_max])\n",
    "    cbar.ax.set_yticklabels([mdates.num2date(cb_min, pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d\"), \\\n",
    "                            mdates.num2date(cb_max, pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d\")])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day, night = split_daynight(file_dataset)\n",
    "day_scatter(day)\n",
    "night_scatter(night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Both during day and night, we see severe violations where indoor=outdoor temp. We want to capture this severity if possible.\n",
    "* At night, in some cases, it is significantly colder indoors than outdoors. Why?\n",
    "* In other cases, we see more persistent yet less severe violations. Capture these too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do Violations Look Like?\n",
    "Should we be looking at:\n",
    "* Consecutive violation hours in the past 24 hrs\n",
    "* Consecutive violation hours in the past 72 hrs\n",
    "* Consecutive violation days in the past week\n",
    "* Percentage violation hours in the past 24 hrs\n",
    "* Percentage violation hours in the past 72 hrs\n",
    "* Percentage violation days in the past week\n",
    "* Severity of each violation\n",
    "* etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluse some outlier users with small uptime for this analysis\n",
    "exclusions=[428, 327, 386]\n",
    "\n",
    "def exclude_users(user_dataset, exclusions):\n",
    "    \"\"\"\n",
    "    Remove certain users from the dataset, given a list of exclusions\n",
    "    :param user_dataset: second dataset from user_import()\n",
    "    :param exclusions: list of users to remove\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    :type exclusions: list\n",
    "    \"\"\"\n",
    "    clean_dataset = user_dataset.copy()\n",
    "    del_ids = []\n",
    "    i = 0\n",
    "    while i < len(clean_dataset):\n",
    "        if clean_dataset[i]['user_id'][0] in exclusions:\n",
    "            clean_dataset.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    return clean_dataset\n",
    "\n",
    "print(len(user_dataset))\n",
    "user_dataset_c = exclude_users(user_dataset, exclusions)\n",
    "print(len(user_dataset))\n",
    "print(len(user_dataset_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutive Violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(input_csv):\n",
    "    \"\"\"\n",
    "    Gets the records of an input csv and formats for easy random access\n",
    "    :param input_csv: path to input csv\n",
    "    :type input_csv: str\n",
    "    :return: dictionary where keys are the timestamps of the inputted file, values are user id and violation occurance\n",
    "    :return type: dict(list)\n",
    "    Contributed by Daniel J., Justin L.\n",
    "    \"\"\"\n",
    "    records = {} \n",
    "    with open(input_csv, newline='') as csv_file:\n",
    "        # skip the first line because it has headers and field names\n",
    "        headers = True\n",
    "        data_reader = csv.reader(csv_file) # instantiate a csv reader\n",
    "        for row in data_reader:\n",
    "            if not headers:\n",
    "                created = datetime.strptime(row[3], \"%Y-%m-%d %H:%M:%S\")\n",
    "                created = created.replace(tzinfo = pytz.utc)\n",
    "                created = created.astimezone(pytz.timezone('US/Eastern'))\n",
    "                # datetime formatting to convert UTC to EST or EDT as appropriate.\n",
    "                # hardcoding timezone here is acceptable since our domain is very constrained.\n",
    "                user_id = row[0]\n",
    "                violation = row[5].lower()\n",
    "                value = (user_id, violation)\n",
    "                records[created] = value # add entries to dictionary\n",
    "            else:\n",
    "                headers = False\n",
    "    return records\n",
    "\n",
    "def read_all_user(inFilePathPerUser, skip):\n",
    "    \"\"\"\n",
    "    Parses through each csv file found in the file path to get all per user records\n",
    "    :param inFilePathPerUser: path to per-user data directory\n",
    "    :type inFilePathPerUser: str\n",
    "    :return: list of dictionaries for per-user records\n",
    "    :rtype: list\n",
    "    Contributed by Jake L., Justin L.\n",
    "    \"\"\"\n",
    "    filePathPerUser =  inFilePathPerUser # file path for the per-user data\n",
    "    listOfFiles = os.listdir(filePathPerUser) # list of all the files in the per-user data directory\n",
    "    recordsAllUsers = list()\n",
    "    for i in range(0, len(listOfFiles)):\n",
    "        if int(listOfFiles[i][:-4]) in skip:\n",
    "            continue\n",
    "        input_csv = filePathPerUser + '/' + listOfFiles[i]\n",
    "        recordsAllUsers.append(get_records(input_csv)) # add each user's dictionary of records to the list\n",
    "    return recordsAllUsers\n",
    "\n",
    "def consecutive_violation_hours(user_record):\n",
    "    \"\"\"\n",
    "    Counts and records the length in hours of all consecutive violations\n",
    "    :param user_record: dictionary where keys are the timestamps of the inputted file, values are user id and violation occurance\n",
    "    :type user_record: dict\n",
    "    :return: dictionary where key is user id, value is a list of the lengths in hours of all consecutive violations\n",
    "    :rtype: dict\n",
    "    Contributed by Justin L.\n",
    "    \"\"\"\n",
    "    consecutive_violation_hours = {}\n",
    "    violations = list()\n",
    "    user_id = list(user_record.values())[0][0]\n",
    "    count = 0\n",
    "    for i in range(0, len(user_record) - 1): # iterate over all of the user's records\n",
    "        time = list(user_record.keys())[i] # get the time of the record\n",
    "        violation = list(user_record.values())[i][1] # get whether or not there is a violation\n",
    "        next_time = list(user_record.keys())[i + 1] # get the time of the next record\n",
    "        time_differential = time - next_time # get the time differential between this record and the next\n",
    "        time_differential_hours = divmod(time_differential.seconds, 3600)[0] # time differential in hours\n",
    "        if violation == 'true': # if there is a violation...\n",
    "            if count == 0: # increase the count but only if the previous record was not a violation\n",
    "                count = count + 1\n",
    "            if time_differential.days == 0 and time_differential_hours < 2 and time_differential_hours >= 1:\n",
    "                count = count + time_differential_hours\n",
    "                # if the amount of time between the records is between an hour and two hours, increase the count by one\n",
    "            else:\n",
    "                if count != 0:\n",
    "                    violations.append(count)\n",
    "                count = 0\n",
    "                # else if the amount of time between the records is more than 2 hours, \n",
    "                # add the current count of consequtive violation hours to the list and reset the count.\n",
    "        else:\n",
    "            if count != 0:\n",
    "                violations.append(count - 1)\n",
    "            count = 0\n",
    "            # if there stops being a violation, add the current count of consequtive violation hours to the list and reset \n",
    "            # the count.\n",
    "    if count != 0:\n",
    "        violations.append(count + 1)\n",
    "    elif list(user_record.values())[len(user_record) - 1][1] == \"true\":\n",
    "        violations.append(count + 1)\n",
    "        \n",
    "    consecutive_violation_hours[user_id] = violations\n",
    "    return consecutive_violation_hours\n",
    "    # NOTE:\n",
    "    # There are some cases in the users' records where there are pieces of 'missing data.'\n",
    "    # These might be a result of the heat seek being turned off for a period of time. \n",
    "    # Commonly, a recording is taken every hour, but in these cases, there may be records taken at intervals longer than 1 hr. \n",
    "    # Hence, it is important to consider the time interval between consecutive records. \n",
    "    # At the extreme, one record may have been taken 10 days after the prior record. And of course, even if both records show\n",
    "    # a violation, these would not be considered consecutive hours of violation.\n",
    "    # In some cases, the time interval between two consecutive records was more than an hour but less than two hours.\n",
    "    # These were still considered to be consecutive hours of violation, but any time interval longer than two hours was\n",
    "    # not considered consecutive hours of violations, because we know too little about what occurred between the interval.\n",
    "    \n",
    "    # Because of this afformentioned issue of 'missing data,' this might be a sign that we shouldn't be considering\n",
    "    # or recording consecutive violation hours to make conclusions. Rather, we may resort to day-wise binning.\n",
    "\n",
    "def plot_hist_consecutive_violation(consecutive_violations):\n",
    "    \"\"\"\n",
    "    Make a bar graph of consecutive hours of violations\n",
    "    :param consecutive_violations: list of the lengths in hours of all consecutive violations\n",
    "    :type consecutive_violations: list\n",
    "    Contributed by Justin L.\n",
    "    Modified by Jake L.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # plot of the data\n",
    "    \n",
    "    ax.hist(consecutive_violations, 89)\n",
    "    ax.set_xlabel('Consecutive Violation Hours')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    #ax.set_title('Histogram of Consecutive violation hours for user ID ' + list(consecutive_violations.keys())[0])\n",
    "    ax.set_title('2017-2018 Heat Season Histogram of Consecutive Violation Hours')\n",
    "#     ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#     if consecutive_hours:\n",
    "#         ax.set_xbound(0, max(consecutive_hours) + 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_records = read_all_user('./data/per_user', exclusions)\n",
    "# bear with me here, converting data formats...\n",
    "# list of dictionaries\n",
    "consec_vios = []\n",
    "for user_record in all_user_records:\n",
    "    consec_vios.append(consecutive_violation_hours(user_record))\n",
    "    \n",
    "# into a single dictionary\n",
    "consec_dict = consec_vios[0]\n",
    "for i in range(1, len(consec_vios)):\n",
    "    consec_dict.update(consec_vios[i])\n",
    "    \n",
    "# into a combined list\n",
    "total_consec = []\n",
    "for user in consec_dict:\n",
    "    total_consec = total_consec + consec_dict[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and plot.\n",
    "print(max(total_consec))\n",
    "plot_hist_consecutive_violation(total_consec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Note that consecutive hours can be across days.\n",
    "* This also doesn't capture when there are no violations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage Violations (over 24 hrs)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vio_per_day(user_dataset):\n",
    "    \"\"\"\n",
    "    Count the number of violations detected per day for everyone\n",
    "    :param user_dataset: second DataFrame returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    perc_list = []\n",
    "    count_list = []\n",
    "    for user in user_dataset_c:\n",
    "        user_df = user.copy()\n",
    "        user_df.set_index('created_at', inplace=True)\n",
    "#       df_count = user_df.groupby(pd.Grouper(level='created_at', freq='D'))['violation'].count()\n",
    "        df_group = user_df.groupby(pd.Grouper(level='created_at', freq='D'))['violation'].sum()\n",
    "        for i in range(len(df_group)):\n",
    "#             if df_count.iloc[i] == 0:\n",
    "#                 perc_list.append(0)\n",
    "#             else:\n",
    "#                 perc_list.append(float(df_group.iloc[i]) / float(df_count.iloc[i]))\n",
    "            count_list.append(float(df_group.iloc[i]))\n",
    "    return count_list\n",
    "\n",
    "def plot_hist_count(count_vio):\n",
    "    \"\"\"\n",
    "    Plot a histogram of the violation counts\n",
    "    :param count_vio: list of binned violations returned by vio_per_day()\n",
    "    :type count_vio: list\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # plot of the data\n",
    "    ax.set_xlim([0,24])\n",
    "    ax.hist(count_vio, 24)\n",
    "    ax.set_xlabel('Violation Measurements per Day')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('2017-2018 Heat Season Histogram of Violation Hours per Day')\n",
    "    plt.show()\n",
    "def plot_hist_count_vio(count_vio):\n",
    "    \"\"\"\n",
    "    Plot a histogram of the violation counts, excluding the bar for no violations\n",
    "    :param count_vio: list of binned violations returned by vio_per_day()\n",
    "    :type count_vio: list\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # plot of the data\n",
    "    ax.set_xlim([1,24])\n",
    "    ax.hist(count_vio, 24)\n",
    "    ax.set_xlabel('Violation Measurements per Day')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('2017-2018 Heat Season Histogram of Violation Hours per Day, >1 Violations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vio = vio_per_day(user_dataset_c)\n",
    "only_vio = [a for a in count_vio if a != 0]\n",
    "only_vio.append(0.0)\n",
    "plot_hist_count(count_vio)\n",
    "plot_hist_count_vio(only_vio)\n",
    "\n",
    "geq_ten = [a for a in only_vio if a >= 10]\n",
    "print('geq_ten: ', len(geq_ten) / (len(only_vio)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* The spike at 16 is if there is a violation during the entirety of daytime.\n",
    "    * I would consider that 'duration severe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between Severity and Frequency? (Show Justin W.'s plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longterm_plot(user_dataset):\n",
    "    \"\"\"\n",
    "    Plot a time coverage plot heatmapped for number of violations per day\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    # Sorted user by duration, determined a priori\n",
    "    sorted_users = ['389', '387', '381', '380', '399', '408', '350', '297', '390', '391', '385', '395', '396', '397', '398', '401', '394', '404', '405', '403', '410', '339', '411', '413', '415', '406', '417', '422', '420', '423', '425', '412', '426', '430', '432', '431', '407', '382', '427', '437', '379', '308', '167', '414', '383', '421', '424', '163', '436', '386', '327', '428']\n",
    "    \n",
    "    # New dataset with binned data for each day\n",
    "    # As in, number of violations per day per user\n",
    "    grouped_users = {}\n",
    "    for user_df in user_dataset:\n",
    "        user_df_i = user_df.set_index('created_at', inplace=False)\n",
    "        df_group = user_df_i.groupby(pd.Grouper(level='created_at', freq='D'))['violation'].sum()\n",
    "        grouped_users[user_df['user_id'][0]] = df_group\n",
    "    \n",
    "    # matplotlib magic\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(17,22))\n",
    "    ax.xaxis_date()\n",
    "    \n",
    "    counter = 1\n",
    "    for user in sorted_users[::-1]:\n",
    "        curr_df = grouped_users[int(user)]\n",
    "        sc = ax.scatter(curr_df.index.values, [counter]*len(curr_df), c=curr_df.values, cmap='plasma', vmin=0, vmax=24)\n",
    "        counter += 1\n",
    "    \n",
    "    ax.set_yticks(range(1, len(sorted_users)+1))\n",
    "    ax.set_yticklabels(sorted_users[::-1])\n",
    "    ax.grid(b=True, which='major', axis='both', linestyle='--', zorder=1)\n",
    "    cbar = plt.colorbar(sc, ax=ax, ticks=range(25), orientation='vertical')\n",
    "\n",
    "    return\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def custom_plot(user_dataset):\n",
    "    \"\"\"\n",
    "    Plot a time coverage plot heatmapped for number of violations per day\n",
    "    :param user_dataset: second dataset returned by user_import()\n",
    "    :type user_dataset: list(DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a color mapping for number of violations\n",
    "    # This says:\n",
    "    # Green from 0~2 violations\n",
    "    # Yellow from 3~9 violations\n",
    "    # Red from 10~24 violations\n",
    "    colors = [(0,1,0)]*3 + [(1,1,0)]*7 + [(1,0,0)] * 14\n",
    "    n_bins = 24\n",
    "    cm = LinearSegmentedColormap.from_list('custom_cm', colors, N=n_bins)\n",
    "    \n",
    "    # Sorted user by duration, determined a priori\n",
    "    sorted_users = ['389', '387', '381', '380', '399', '408', '350', '297', '390', '391', '385', '395', '396', '397', '398', '401', '394', '404', '405', '403', '410', '339', '411', '413', '415', '406', '417', '422', '420', '423', '425', '412', '426', '430', '432', '431', '407', '382', '427', '437', '379', '308', '167', '414', '383', '421', '424', '163', '436', '386', '327', '428']\n",
    "    \n",
    "    # New dataset with binned data for each day\n",
    "    # As in, number of violations per day per user\n",
    "    grouped_users = {}\n",
    "    for user_df in user_dataset:\n",
    "        user_df_i = user_df.set_index('created_at', inplace=False)\n",
    "        df_group = user_df_i.groupby(pd.Grouper(level='created_at', freq='D'))['violation'].sum()\n",
    "        grouped_users[user_df['user_id'][0]] = df_group\n",
    "        \n",
    "    # matplotlib magic\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(17,22))\n",
    "    ax.xaxis_date()\n",
    "    \n",
    "    counter = 1\n",
    "    for user in sorted_users[::-1]:\n",
    "        curr_df = grouped_users[int(user)]\n",
    "        sc = ax.scatter(curr_df.index.values, [counter]*len(curr_df), c=curr_df.values, cmap=cm, vmin=0, vmax=24)\n",
    "        counter += 1\n",
    "    \n",
    "    ax.set_yticks(range(1, len(sorted_users)+1))\n",
    "    ax.set_yticklabels(sorted_users[::-1])\n",
    "    ax.grid(b=True, which='major', axis='both', linestyle='--', zorder=1)\n",
    "\n",
    "    \n",
    "    cbar = plt.colorbar(sc, ax=ax, ticks=range(25), orientation='vertical')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_plot(user_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_plot(user_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
